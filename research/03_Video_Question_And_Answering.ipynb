{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Question And Answering using Gemini Pro Vision Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Only video frames is supported at the moment based on which questions can be asked and model will answer based on the frames of the video. Audio is not supported.\n",
    "\n",
    "For now, videos are required to uploaded to Google Cloud Storage and will work on publicly available link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isham993/Desktop/Programming-Tutorials/2023-Data-Science/google-gemini-project/getting-started-with-gemini-models-demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isham993/mambaforge/envs/google_gemini_environment2/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate Google Service Account Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully authenticated with Google service account.\n"
     ]
    }
   ],
   "source": [
    "authenticate_google_service_account_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(GEMINI_PRO_VISION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of video url in Google Storage:\n",
    "\n",
    "- `file_path = \"github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"`\n",
    "- `video_url = f\"https://storage.googleapis.com/{file_path}\"`\n",
    "\n",
    "The model only accepts uri for videos at this point. \n",
    "- `video_uri = f\"gs://{file_path}\"`\n",
    "\n",
    "So, `https://storage.googleapis.com/` will be replaced with `gs://` when passing to `Part.from_uri` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting JSON Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets ask question to the video showcasing Pixel8 commercial.\n",
    "\n",
    "<video width=\"500\" height=\"500\" controls>\n",
    "  <source src=\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      " ```json\n",
      "{\n",
      "  \"profession\": \"photographer\",\n",
      "  \"features\": \"Night Sight, Video Boost\",\n",
      "  \"city\": \"Tokyo\"\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "What is the profession of the main person?\n",
    "What are the main features of the phone highlighted?\n",
    "Which city was this recorded in?\n",
    "Provide the answer JSON.\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting tags of objects throughout the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini pro vision model also is able to extract tags from video. Lets see how it does for the following video. \n",
    "\n",
    "<video width=\"500\" height=\"500\" controls>\n",
    "  <source src=\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/photography.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      " - The video shows a man in a hat taking pictures of some artifacts on a table.\n",
      "- The man is taking pictures of the artifacts.\n",
      "- #photography, #art, #travel, #vacation, #beach, #sun, #sand, #water, #nature, #explore"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "- What is in the video?\n",
    "- What is the action in the video?\n",
    "- Provide 10 best tags for this video?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/photography.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving extra information beyond the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a video of O-Train Confederation Line. Lets see how to extract information beyond the video that is input to the model. \n",
    "\n",
    "<video width=\"500\" height=\"500\" controls>\n",
    "  <source src=\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/ottawatrain3.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      " This is the O-Train Confederation Line. It is a light rail line that runs from Tunney's Pasture to Blair. The stations on the line are:\n",
      "\n",
      "* Tunney's Pasture\n",
      "* Bayview\n",
      "* Pimisi\n",
      "* Dominion\n",
      "* Carleton\n",
      "* Confederation\n",
      "* City Hall\n",
      "* Parliament\n",
      "* Rideau\n",
      "* uOttawa\n",
      "* Lees\n",
      "* Hurdman\n",
      "* Cyrville\n",
      "* St. Laurent\n",
      "* Blair"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Which line is this?\n",
    "where does it go?\n",
    "What are the stations/stops?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/ottawatrain3.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_gemini_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
